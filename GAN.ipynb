{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim,128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid(),           \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.disc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh(),            \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.gen(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4 # 0.0003\n",
    "z_dim = 64\n",
    "image_dim = 28*28*1\n",
    "batch_size = 512\n",
    "num_epochs = 50\n",
    "\n",
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim,image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size,z_dim)).to(device)\n",
    "t_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]\n",
    "    )\n",
    "\n",
    "dataset = datasets.MNIST('./data',download=True,train=True,transform=t_transforms)\n",
    "loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "opt_disc = optim.Adam(disc.parameters(),lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(),lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")\n",
    "step = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0/50] \\  loss d : 0.649, lossg: 0.677\n",
      "epoch [1/50] \\  loss d : 0.400, lossg: 1.059\n",
      "epoch [2/50] \\  loss d : 0.075, lossg: 2.505\n",
      "epoch [3/50] \\  loss d : 0.276, lossg: 1.162\n",
      "epoch [4/50] \\  loss d : 0.458, lossg: 0.830\n",
      "epoch [5/50] \\  loss d : 0.473, lossg: 0.945\n",
      "epoch [6/50] \\  loss d : 0.432, lossg: 1.138\n",
      "epoch [7/50] \\  loss d : 0.577, lossg: 0.813\n",
      "epoch [8/50] \\  loss d : 0.366, lossg: 1.377\n",
      "epoch [9/50] \\  loss d : 0.604, lossg: 0.986\n",
      "epoch [10/50] \\  loss d : 0.495, lossg: 1.117\n",
      "epoch [11/50] \\  loss d : 0.916, lossg: 0.608\n",
      "epoch [12/50] \\  loss d : 0.898, lossg: 0.597\n",
      "epoch [13/50] \\  loss d : 0.387, lossg: 1.387\n",
      "epoch [14/50] \\  loss d : 0.404, lossg: 1.317\n",
      "epoch [15/50] \\  loss d : 0.725, lossg: 0.772\n",
      "epoch [16/50] \\  loss d : 0.906, lossg: 0.555\n",
      "epoch [17/50] \\  loss d : 0.804, lossg: 0.700\n",
      "epoch [18/50] \\  loss d : 0.368, lossg: 1.310\n",
      "epoch [19/50] \\  loss d : 0.206, lossg: 1.952\n",
      "epoch [20/50] \\  loss d : 0.642, lossg: 0.784\n",
      "epoch [21/50] \\  loss d : 0.655, lossg: 0.844\n",
      "epoch [22/50] \\  loss d : 0.301, lossg: 1.466\n",
      "epoch [23/50] \\  loss d : 0.687, lossg: 0.737\n",
      "epoch [24/50] \\  loss d : 0.612, lossg: 0.928\n",
      "epoch [25/50] \\  loss d : 0.933, lossg: 0.692\n",
      "epoch [26/50] \\  loss d : 0.390, lossg: 1.400\n",
      "epoch [27/50] \\  loss d : 0.439, lossg: 1.216\n",
      "epoch [28/50] \\  loss d : 0.418, lossg: 1.425\n",
      "epoch [29/50] \\  loss d : 0.732, lossg: 0.836\n",
      "epoch [30/50] \\  loss d : 0.557, lossg: 0.972\n",
      "epoch [31/50] \\  loss d : 0.452, lossg: 1.339\n",
      "epoch [32/50] \\  loss d : 0.438, lossg: 1.228\n",
      "epoch [33/50] \\  loss d : 0.606, lossg: 0.889\n",
      "epoch [34/50] \\  loss d : 0.644, lossg: 0.952\n",
      "epoch [35/50] \\  loss d : 0.477, lossg: 1.229\n",
      "epoch [36/50] \\  loss d : 0.266, lossg: 1.666\n",
      "epoch [37/50] \\  loss d : 0.508, lossg: 1.195\n",
      "epoch [38/50] \\  loss d : 0.415, lossg: 1.500\n",
      "epoch [39/50] \\  loss d : 0.465, lossg: 1.223\n",
      "epoch [40/50] \\  loss d : 0.292, lossg: 1.644\n",
      "epoch [41/50] \\  loss d : 0.540, lossg: 1.021\n",
      "epoch [42/50] \\  loss d : 0.671, lossg: 0.928\n",
      "epoch [43/50] \\  loss d : 0.321, lossg: 1.572\n",
      "epoch [44/50] \\  loss d : 0.837, lossg: 0.741\n",
      "epoch [45/50] \\  loss d : 0.570, lossg: 1.115\n",
      "epoch [46/50] \\  loss d : 0.825, lossg: 0.750\n",
      "epoch [47/50] \\  loss d : 0.542, lossg: 1.143\n",
      "epoch [48/50] \\  loss d : 0.493, lossg: 1.190\n",
      "epoch [49/50] \\  loss d : 0.614, lossg: 0.942\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,num_epochs):\n",
    "    for i,(real,_) in enumerate(loader):\n",
    "        real = real.view(-1,image_dim).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        \n",
    "        ## 판별기 학습\n",
    "        noise = torch.randn(batch_size,z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        # disc_real = torch.Size([32]) 판별 결과, 0~1사이 값\n",
    "        lossD_real = criterion(disc_real,torch.ones_like(disc_real))\n",
    "\n",
    "\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_fake+lossD_real) /2\n",
    "        \n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        \n",
    "        # 제너레이터 학습\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output,torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if i == 0:\n",
    "            print(f\"epoch [{epoch}/{num_epochs}] \\ \",f\"loss d : {lossD:.3f}, lossg: {lossG:.3f}\" )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
    "            data = real.reshape(-1,1,28,28)\n",
    "            img_grid_fake = torchvision.utils.make_grid(fake,normalize=True)\n",
    "            img_grid_real = torchvision.utils.make_grid(data,normalize=True)\n",
    "            \n",
    "            writer_fake.add_image(\"엠니스트 fake\",img_grid_fake,global_step=step)\n",
    "            \n",
    "            writer_real.add_image(\"엠니스트 fake\",img_grid_real,global_step=step)\n",
    "                    \n",
    "            step +=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d55d3335eb288fc7a3982e93953789f2123700bb0edcab51ee53f4da0264440"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
